{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph, to_dense_adj, to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \n",
    "    correct = y_pred.eq(y_true).double()\n",
    "    correct = correct.sum().item()\n",
    "\n",
    "    accuracy_value = correct / len(y_true)\n",
    "    # 计算准确率的标准差\n",
    "    squared_error = (correct - accuracy_value * len(y_true))**2\n",
    "    variance = squared_error / len(y_true)\n",
    "    accuracy_std = np.sqrt(variance)\n",
    "\n",
    "    return accuracy_value, accuracy_std\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        out = self.conv2(x, edge_index)\n",
    "        return x, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "================================================================================\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "GCN(\n",
      "  (conv1): GCNConv(1433, 512)\n",
      "  (conv2): GCNConv(512, 7)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print('='*80)\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "\n",
    "\n",
    "model = GCN(dataset.num_features, 512, dataset.num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0\n",
    "num_epochs = 200\n",
    "train_losses, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, out = model(data.x, data.edge_index)\n",
    "    loss = cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    train_losses.append(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        x, out = model(data.x, data.edge_index)\n",
    "        val_loss = cross_entropy(out[data.val_mask], data.y[data.val_mask])\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "        val_pred = out.argmax(dim=1)\n",
    "        val_acc,_ = accuracy(val_pred[data.val_mask], data.y[data.val_mask])\n",
    "\n",
    "    if val_acc >= best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Loss: {val_loss:.4f}, Val ACC: {val_acc:.4f}')\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('figs/loss_curve_gcn_mrl.png')\n",
    "\n",
    "model.eval()\n",
    "model = best_model\n",
    "x, out = model(data.x, data.edge_index)\n",
    "test_pred = out.argmax(dim=1)\n",
    "test_acc, test_acc_std = accuracy(test_pred[data.test_mask], data.y[data.test_mask])\n",
    "print(f'Test Accuracy: {test_acc:.4f}, Test Acc std: {test_acc_std:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
